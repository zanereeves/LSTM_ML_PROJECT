{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypWRNwe_KmUB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from keras.utils import np_utils\n",
        "import time\n",
        "from wordcloud import WordCloud\n",
        "from matplotlib import animation\n",
        "from matplotlib.animation import FuncAnimation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "!wget https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/miniproject3/data/shakespeare.txt\n",
        "!wget https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/miniproject3/data/Syllable_dictionary.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLycOM4qK9X8",
        "outputId": "3294ce79-cf80-42a8-8bda-53e1cb05f425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-13 03:21:37--  https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/miniproject3/data/shakespeare.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98029 (96K) [text/plain]\n",
            "Saving to: ‘shakespeare.txt.2’\n",
            "\n",
            "\rshakespeare.txt.2     0%[                    ]       0  --.-KB/s               \rshakespeare.txt.2   100%[===================>]  95.73K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-03-13 03:21:37 (44.2 MB/s) - ‘shakespeare.txt.2’ saved [98029/98029]\n",
            "\n",
            "--2023-03-13 03:21:37--  https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/miniproject3/data/Syllable_dictionary.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30174 (29K) [text/plain]\n",
            "Saving to: ‘Syllable_dictionary.txt.2’\n",
            "\n",
            "Syllable_dictionary 100%[===================>]  29.47K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-13 03:21:37 (99.2 MB/s) - ‘Syllable_dictionary.txt.2’ saved [30174/30174]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "VTlkoqhlLoJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syllable_dict = {}\n",
        "\n",
        "with open('Syllable_dictionary.txt') as f:\n",
        "\n",
        "  for line in f:\n",
        "    line = line[:-1]\n",
        "    info = line.split(' ')\n",
        "    if len(info) != 2:\n",
        "      if info[1] in ['E1','E2','E3']:\n",
        "        info.remove(info[1])\n",
        "      elif info[2] in ['E1','E2','E3']:\n",
        "        info.remove(info[2])\n",
        "    syllable_dict[info[0]] = int (info[1])"
      ],
      "metadata": {
        "id": "oQjT4O-ETocI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_list = []\n",
        "\n",
        "with open('shakespeare.txt') as f:\n",
        "  strng = f.read()\n",
        "\n",
        "strng = strng.lower()\n",
        "strng = strng.translate(str.maketrans('', '', string.digits))\n",
        "strng = strng.translate(str.maketrans('', '', string.punctuation)).replace('\\n', ' ').strip()\n",
        "\n",
        "int_encoding = {}\n",
        "char_encoding = {}\n",
        "\n",
        "\n",
        "encoded_strng = []\n",
        "for i in range(26):\n",
        "  int_encoding[i] = chr(97+i)\n",
        "  char_encoding[chr(97+i)] = i\n",
        "\n",
        "int_encoding[26] = ' '\n",
        "char_encoding[' '] = 26\n",
        "\n",
        "for i in range(len(strng)):\n",
        "  current_char = strng[i]\n",
        "  encoded_strng.append(char_encoding[current_char])\n",
        "\n",
        "print(int_encoding)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO11rC0SL9nC",
        "outputId": "ac28a5ef-df05-4cb0-dced-7bd0a1e284ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: ' '}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# go thru lines\n",
        "# remove unnecessary stuff\n",
        "# tokenize with the tweet tokenizer\n",
        "# loop thru words, make lowercase\n",
        "# make the dictionary from numbers to characters\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, len(encoded_strng) - 40-1 , 1):\n",
        "  seq_in = encoded_strng[i:i + 40]\n",
        "  seq_out = encoded_strng[i + 40]\n",
        "\n",
        "  if seq_out==1: #Skip samples where target word is OOV\n",
        "    continue\n",
        "\n",
        "  dataX.append(seq_in)\n",
        "  dataY.append(seq_out)\n",
        "\n",
        "\n",
        "train_x = np.array(dataX)\n",
        "train_y = np.array(np_utils.to_categorical(dataY))\n"
      ],
      "metadata": {
        "id": "CULuJF12LQDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine import input_layer\n",
        "\n",
        "model = keras.Sequential([\n",
        "    tf.keras.layers.Embedding(28, 27),\n",
        "    tf.keras.layers.LSTM(100, input_shape=(None, 27)),\n",
        "    tf.keras.layers.Lambda(lambda x: x / 1),\n",
        "    tf.keras.layers.Dense(27, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_x, train_y, epochs=4)"
      ],
      "metadata": {
        "id": "5lC6eQGUu9q8",
        "outputId": "b47ebd20-1de1-4f85-d810-c0370ac83e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "2915/2915 [==============================] - 82s 27ms/step - loss: 2.1335 - accuracy: 0.3712\n",
            "Epoch 2/4\n",
            "2915/2915 [==============================] - 78s 27ms/step - loss: 1.7843 - accuracy: 0.4591\n",
            "Epoch 3/4\n",
            "2915/2915 [==============================] - 79s 27ms/step - loss: 1.6641 - accuracy: 0.4934\n",
            "Epoch 4/4\n",
            "2915/2915 [==============================] - 80s 28ms/step - loss: 1.5893 - accuracy: 0.5121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb7b1f2580>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "je8TlDcs6eY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strng = 'shall i compare thee to a summers day'\n",
        "\n",
        "converted_strng = []\n",
        "for char in strng:\n",
        "  converted_strng.append(char_encoding[char])\n",
        "num_str = converted_strng\n",
        "\n",
        "print(num_str)\n",
        "result_mat = []\n",
        "for i in range(80):\n",
        "  token_list = tf.keras.preprocessing.sequence.pad_sequences([num_str], maxlen=81-1, padding='pre')\n",
        "  predict_x=model.predict(token_list)\n",
        "  classes_x = np.random.choice(len(predict_x.flatten()), p=predict_x.flatten())\n",
        "  result_mat.append(classes_x)\n",
        "  num_str.append(classes_x)\n",
        "\n",
        "\n",
        "print(result_mat)\n",
        "print(num_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ogqBTwA6rZx",
        "outputId": "95f019a7-f159-4059-99f4-ab75a61bc25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 7, 0, 11, 11, 26, 8, 26, 2, 14, 12, 15, 0, 17, 4, 26, 19, 7, 4, 4, 26, 19, 14, 26, 0, 26, 18, 20, 12, 12, 4, 17, 18, 26, 3, 0, 24]\n",
            "1/1 [==============================] - 0s 370ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[26, 3, 4, 17, 2, 4, 26, 19, 7, 4, 13, 26, 11, 8, 6, 7, 19, 26, 19, 0, 19, 8, 13, 6, 26, 3, 14, 19, 7, 26, 0, 11, 11, 26, 5, 0, 17, 8, 5, 4, 3, 26, 12, 24, 26, 2, 4, 4, 13, 26, 22, 8, 19, 7, 14, 17, 26, 0, 18, 26, 10, 4, 18, 4, 2, 20, 11, 4, 18, 26, 19, 4, 11, 11, 26, 8, 19, 26, 18, 20]\n",
            "[18, 7, 0, 11, 11, 26, 8, 26, 2, 14, 12, 15, 0, 17, 4, 26, 19, 7, 4, 4, 26, 19, 14, 26, 0, 26, 18, 20, 12, 12, 4, 17, 18, 26, 3, 0, 24, 26, 3, 4, 17, 2, 4, 26, 19, 7, 4, 13, 26, 11, 8, 6, 7, 19, 26, 19, 0, 19, 8, 13, 6, 26, 3, 14, 19, 7, 26, 0, 11, 11, 26, 5, 0, 17, 8, 5, 4, 3, 26, 12, 24, 26, 2, 4, 4, 13, 26, 22, 8, 19, 7, 14, 17, 26, 0, 18, 26, 10, 4, 18, 4, 2, 20, 11, 4, 18, 26, 19, 4, 11, 11, 26, 8, 19, 26, 18, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finished_str = []\n",
        "for i in range(len(np.array(num_str).flatten())):\n",
        "  finished_str.append(int_encoding[num_str[i]])\n",
        "\n",
        "print(''.join(finished_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPFKidouEQUJ",
        "outputId": "f23873c9-b868-4d96-a098-ec943b490e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shall i compare thee to a summers day derce then light tating doth all farifed my ceen withor as kesecules tell it su\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine import input_layer\n",
        "\n",
        "model = keras.Sequential([\n",
        "    tf.keras.layers.Embedding(28, 27),\n",
        "    tf.keras.layers.LSTM(100, input_shape=(None, 27)),\n",
        "    tf.keras.layers.Lambda(lambda x: x *.75),\n",
        "    tf.keras.layers.Dense(27, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_x, train_y, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSXHjTMGG2on",
        "outputId": "7eb0cfb8-357f-4f48-e331-0716c9150b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "2915/2915 [==============================] - 82s 27ms/step - loss: 2.2190 - accuracy: 0.3501\n",
            "Epoch 2/4\n",
            "2915/2915 [==============================] - 79s 27ms/step - loss: 1.9097 - accuracy: 0.4255\n",
            "Epoch 3/4\n",
            "2915/2915 [==============================] - 80s 27ms/step - loss: 1.8019 - accuracy: 0.4567\n",
            "Epoch 4/4\n",
            "2915/2915 [==============================] - 81s 28ms/step - loss: 1.7334 - accuracy: 0.4732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb79aa64c0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strng = 'shall i compare thee to a summers day'\n",
        "\n",
        "converted_strng = []\n",
        "for char in strng:\n",
        "  converted_strng.append(char_encoding[char])\n",
        "num_str = converted_strng\n",
        "\n",
        "print(num_str)\n",
        "result_mat = []\n",
        "for i in range(80):\n",
        "  token_list = tf.keras.preprocessing.sequence.pad_sequences([num_str], maxlen=81-1, padding='pre')\n",
        "  predict_x=model.predict(token_list)\n",
        "  classes_x = np.random.choice(len(predict_x.flatten()), p=predict_x.flatten())\n",
        "  result_mat.append(classes_x)\n",
        "  num_str.append(classes_x)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jf_Y9fKISA1",
        "outputId": "4beda566-efbf-4c31-aedb-2281bfc40526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 7, 0, 11, 11, 26, 8, 26, 2, 14, 12, 15, 0, 17, 4, 26, 19, 7, 4, 4, 26, 19, 14, 26, 0, 26, 18, 20, 12, 12, 4, 17, 18, 26, 3, 0, 24]\n",
            "1/1 [==============================] - 0s 377ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finished_str = []\n",
        "for i in range(len(np.array(num_str).flatten())):\n",
        "  finished_str.append(int_encoding[num_str[i]])\n",
        "\n",
        "print(''.join(finished_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EPrNeFxIVEs",
        "outputId": "f46203a5-5497-4c12-97f9-6b20946b48b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shall i compare thee to a summers day yoy me priwy dims nut telce out womerines doth of love the sing to held pcuedes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine import input_layer\n",
        "\n",
        "model = keras.Sequential([\n",
        "    tf.keras.layers.Embedding(28, 27),\n",
        "    tf.keras.layers.LSTM(100, input_shape=(None, 27)),\n",
        "    tf.keras.layers.Lambda(lambda x: x *.25),\n",
        "    tf.keras.layers.Dense(27, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_x, train_y, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsgoUKrWIa0a",
        "outputId": "d76ed126-97f3-4b99-b743-7073ef935fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "2915/2915 [==============================] - 84s 28ms/step - loss: 2.3435 - accuracy: 0.3220\n",
            "Epoch 2/4\n",
            "2915/2915 [==============================] - 80s 27ms/step - loss: 2.0208 - accuracy: 0.3972\n",
            "Epoch 3/4\n",
            "2915/2915 [==============================] - 81s 28ms/step - loss: 1.9154 - accuracy: 0.4233\n",
            "Epoch 4/4\n",
            "2915/2915 [==============================] - 81s 28ms/step - loss: 1.8468 - accuracy: 0.4437\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb7ad09910>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strng = 'shall i compare thee to a summers day'\n",
        "\n",
        "converted_strng = []\n",
        "for char in strng:\n",
        "  converted_strng.append(char_encoding[char])\n",
        "num_str = converted_strng\n",
        "\n",
        "print(num_str)\n",
        "result_mat = []\n",
        "for i in range(80):\n",
        "  token_list = tf.keras.preprocessing.sequence.pad_sequences([num_str], maxlen=81-1, padding='pre')\n",
        "  predict_x=model.predict(token_list)\n",
        "  classes_x = np.random.choice(len(predict_x.flatten()), p=predict_x.flatten())\n",
        "  result_mat.append(classes_x)\n",
        "  num_str.append(classes_x)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTVtFJb2J0lJ",
        "outputId": "fa855786-41ec-4075-853e-ddb78bd440eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 7, 0, 11, 11, 26, 8, 26, 2, 14, 12, 15, 0, 17, 4, 26, 19, 7, 4, 4, 26, 19, 14, 26, 0, 26, 18, 20, 12, 12, 4, 17, 18, 26, 3, 0, 24]\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finished_str = []\n",
        "for i in range(len(np.array(num_str).flatten())):\n",
        "  finished_str.append(int_encoding[num_str[i]])\n",
        "\n",
        "print(''.join(finished_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6LoeZnfJ3dw",
        "outputId": "cfced028-08b0-4eeb-de25-ba7dd0c3e7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shall i compare thee to a summers day the thertt iluve tpars evan tht the worchentt waen thify puromt fire   as when \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine import input_layer\n",
        "\n",
        "model = keras.Sequential([\n",
        "    tf.keras.layers.Embedding(28, 27),\n",
        "    tf.keras.layers.LSTM(100, input_shape=(None, 27)),\n",
        "    tf.keras.layers.Lambda(lambda x: x *1.5),\n",
        "    tf.keras.layers.Dense(27, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_x, train_y, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEPvhkbFKNZi",
        "outputId": "acd387e5-e4f2-4c43-cfc4-04260a0a4723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "2915/2915 [==============================] - 82s 27ms/step - loss: 2.0923 - accuracy: 0.3809\n",
            "Epoch 2/4\n",
            "2915/2915 [==============================] - 79s 27ms/step - loss: 1.7408 - accuracy: 0.4729\n",
            "Epoch 3/4\n",
            "2915/2915 [==============================] - 81s 28ms/step - loss: 1.6192 - accuracy: 0.5052\n",
            "Epoch 4/4\n",
            "2915/2915 [==============================] - 89s 31ms/step - loss: 1.5431 - accuracy: 0.5220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb7b196790>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strng = 'shall i compare thee to a summers day'\n",
        "\n",
        "converted_strng = []\n",
        "for char in strng:\n",
        "  converted_strng.append(char_encoding[char])\n",
        "num_str = converted_strng\n",
        "\n",
        "print(num_str)\n",
        "result_mat = []\n",
        "for i in range(80):\n",
        "  token_list = tf.keras.preprocessing.sequence.pad_sequences([num_str], maxlen=81-1, padding='pre')\n",
        "  predict_x=model.predict(token_list)\n",
        "  classes_x = np.random.choice(len(predict_x.flatten()), p=predict_x.flatten())\n",
        "  result_mat.append(classes_x)\n",
        "  num_str.append(classes_x)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNGYEFVyLlAl",
        "outputId": "e392ad41-4217-4ec9-fee3-435ee535ac66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 7, 0, 11, 11, 26, 8, 26, 2, 14, 12, 15, 0, 17, 4, 26, 19, 7, 4, 4, 26, 19, 14, 26, 0, 26, 18, 20, 12, 12, 4, 17, 18, 26, 3, 0, 24]\n",
            "1/1 [==============================] - 0s 398ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finished_str = []\n",
        "for i in range(len(np.array(num_str).flatten())):\n",
        "  finished_str.append(int_encoding[num_str[i]])\n",
        "\n",
        "print(''.join(finished_str))\n",
        "\n",
        "\n",
        "print(len(finished_str))\n",
        "print(len(strng))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dgzt4SKLz9F",
        "outputId": "7e089079-0aef-4e24-dc07-a43cc099a2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shall i compare thee to a summers day seems in that those thoush i carth detoy the wos with likes you   every with li\n",
            "117\n",
            "37\n"
          ]
        }
      ]
    }
  ]
}